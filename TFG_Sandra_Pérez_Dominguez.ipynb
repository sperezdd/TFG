{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFG-Sandra_Pérez_Dominguez.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sperezdd/TFG/blob/master/TFG_Sandra_P%C3%A9rez_Dominguez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeQ9PTVelL9H",
        "colab_type": "text"
      },
      "source": [
        "**Montar** sobre un drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZdPu_wDj3eF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change to assignment directory ('TDImagen_Practicas/P9_P10' by default)\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/TFG')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8KAj2yzRGVs",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHeuYUuzlbFT",
        "colab_type": "text"
      },
      "source": [
        "**Librerias** necesarias para la realizacion del proyecto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfGv3msLloXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy  as np\n",
        "import matplotlib.pyplot as plt # Importa la librería matplotlib\n",
        "import cv2 #Importa la librería opencv\n",
        "import csv\n",
        "import glob\n",
        "\n",
        "%tensorflow_version 2.1\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Dense, Flatten,Dropout,Input, BatchNormalization,GlobalAveragePooling2D, Concatenate, UpSampling2D,Add, Multiply\n",
        "from tensorflow.keras.activations import relu,sigmoid\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing import image as preprocessing_image\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
        "from tensorflow.keras import utils \n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.metrics import AUC\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "from sklearn.metrics import roc_auc_score,roc_curve,average_precision_score,auc, precision_score\n",
        "import skimage.transform as st\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "plt.style.use('default')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV3vlZm0mNTZ",
        "colab_type": "text"
      },
      "source": [
        "**Cargamos** los path \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSq8JHyJX0Ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dirname = os.path.join(os.getcwd(),'imagenes_y_etiquetas/part_3')\n",
        "json_dirname = os.path.join(os.getcwd(),'imagenes_y_etiquetas/part_2')\n",
        "\n",
        "dataset_path = dirname + os.sep \n",
        "print(\"Cargando dateset de: \",dataset_path)\n",
        "\n",
        "train_path = dataset_path + 'train' + os.sep\n",
        "print(\"train path: \", train_path)\n",
        "\n",
        "val_path = dataset_path + 'validation' + os.sep\n",
        "print(\"validation path: \", val_path)\n",
        "\n",
        "test_path = dataset_path + 'test' + os.sep\n",
        "print(\"Test path: \", test_path)\n",
        "\n",
        "categories = [\"melanoma\", \"seborrheic_keratosis\",\"nevus\"]\n",
        "print(\"La clasificacion se hara sobre las siguientes categorias: \" + categories[0] + \", \" + categories[1] + \",\" + categories[2])\n",
        "\n",
        "train_groundTruth_path = train_path + 'ISIC-2017_Training_Part3_GroundTruth.csv'\n",
        "print(\"Las etiquetas de entrenamiento estan en: \", train_groundTruth_path)\n",
        "\n",
        "val_groundTruth_path = val_path + 'ISIC-2017_Validation_Part3_GroundTruth.csv'\n",
        "print(\"Las etiquetas de validacion estan en: \", val_groundTruth_path)\n",
        "\n",
        "test_groundTruth_path = test_path + 'ISIC-2017_Test_v2_Part3_GroundTruth.csv'\n",
        "print(\"Las etiquetas de test estan en: \", test_groundTruth_path)\n",
        "\n",
        "x_val_original = [] + sorted(glob.glob(val_path + 'ISIC-2017_Validation_Data' + '/*.jpg'))\n",
        "x_val_original_superpixels = [] + sorted(glob.glob(val_path + 'ISIC-2017_Validation_Data' + '/*.png'))\n",
        "\n",
        "#cojo solo los .jpg de las imagenes de test. Tambien habia metadata.\n",
        "x_test_original = [] + sorted(glob.glob(test_path +'ISIC-2017_Test_v2_Data' + '/*.jpg')) \n",
        "x_test_original_superpixels = [] + sorted(glob.glob(test_path + 'ISIC-2017_Test_v2_Data' + '/*.png'))\n",
        "json_test_path = [] + sorted(glob.glob(json_dirname + os.sep + 'test' + os.sep + 'ISIC-2017_Test_v2_Part2_GroundTruth' + '/*.json'))\n",
        "\n",
        "#cojo solo los .jpg de las imagenes de validation. Tambien habia metadata.\n",
        "x_train_original = [] + sorted(glob.glob(train_path + 'ISIC-2017_Training_Data' + '/*.jpg'))\n",
        "x_train_original_superpixels = [] + sorted(glob.glob(train_path + 'ISIC-2017_Training_Data' + '/*.png'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRzrb5UtZjEN",
        "colab_type": "text"
      },
      "source": [
        "# FUNCIONES\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXYKc3LXukqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Funciones para guardar las mascaras de estructuras y los mapas de atención\n",
        "\n",
        "def saveInFolderSuperpixels(path_mask, y_label, mask):\n",
        "  set = path_mask.split(\"/\")[7]\n",
        "  name = path_mask.split(\"/\")[9]\n",
        "  if(y_label == 0):\n",
        "    category = \"nevus\"\n",
        "  else:\n",
        "    category = \"melanoma\"\n",
        "  path = os.path.join(os.getcwd(),'imagenes_y_etiquetas') + os.sep + \"superpixels\" + os.sep + set + os.sep + category + os.sep + name\n",
        "  print(path)\n",
        "  print(\"guardadaaaaa\")\n",
        "  preprocessing_image.save_img(path, preprocessing_image.array_to_img(mask), data_format=None, file_format=None)\n",
        " # newPath = shutil.copy(path_image, path)\n",
        "  return \n",
        "\n",
        "def saveMap(map, path, image_,y_label):\n",
        "   set = path.split(\"/\")[7]\n",
        "   name = path.split(\"/\")[9]\n",
        "   if(y_label == 0):\n",
        "     category = \"nevus\"\n",
        "   else:\n",
        "     category = \"melanoma\"\n",
        "   path = os.path.join(os.getcwd(),'imagenes_y_etiquetas') + os.sep +\"attention\" + os.sep + set + os.sep  + category + os.sep + map + os.sep + name\n",
        "   print(image_.shape)\n",
        "   preprocessing_image.save_img(path, image_, data_format=None, file_format=None)\n",
        "   return\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWV3muf4OEeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Funcion para el preprocesado de las imagenes de entrenamiento. Recorta la imagenes 0.8*max(height,weight) sobre el centro de la imagen\n",
        "def crop(img):\n",
        "  high = img.shape[0]\n",
        "  weight = img.shape[1]\n",
        "  lado = round(0.8*min(high,weight))\n",
        "  y1 = round((high-lado)/2)\n",
        "  y2 = high - y1\n",
        "  x1= round((weight-lado)/2)\n",
        "  x2 = weight - x1\n",
        "  image_croped = img[y1:y2,x1:x2]\n",
        "  return preprocessing_image.img_to_array(image_croped)\n",
        "\n",
        "#Funcion que normaliza la imagen\n",
        "def normalized(img, mean_r,mean_g,mean_b):\n",
        "  img_r = np.asarray(img[:,:,0]).astype(float) - mean_r\n",
        "  img_g = np.asarray(img[:,:,1]).astype(float) - mean_g\n",
        "  img_b = np.asarray(img[:,:,2]).astype(float) - mean_b\n",
        "  image = np.asarray(img).astype(float)\n",
        "  image[:,:,0] = img_r\n",
        "  image[:,:,1] = img_g\n",
        "  image[:,:,2] = img_b\n",
        "  return image\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21yaSXFaaGe2",
        "colab_type": "text"
      },
      "source": [
        "#DATA GENERATOR\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjp1aidRNnPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DATA GENERATOR\n",
        "\n",
        "def preprocessed_input(image):\n",
        "  img = st.resize(image, (224, 224))\n",
        "  img_normalized = normalized(img,123.68,116.779,103.939)\n",
        "  return img_normalized\n",
        "  \n",
        "train_datagen = preprocessing_image.ImageDataGenerator(rescale = None,horizontal_flip=True,\n",
        "                                   vertical_flip=True,\n",
        "                                   rotation_range=90,\n",
        "                                   preprocessing_function = preprocessed_input)\n",
        "\n",
        "\n",
        "datagen = preprocessing_image.ImageDataGenerator(preprocessing_function = preprocessed_input)\n",
        "\n",
        "train_path = os.path.join(os.getcwd(),'imagenes_y_etiquetas') + os.sep + \"recortadas\" + os.sep + \"train\"\n",
        "\n",
        "validation_path = os.path.join(os.getcwd(),'imagenes_y_etiquetas') + os.sep + \"recortadas\" + os.sep + \"validation\"\n",
        "\n",
        "test_path = os.path.join(os.getcwd(),'imagenes_y_etiquetas') + os.sep + \"recortadas\" + os.sep + \"test\"\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_path,\n",
        "        color_mode='rgb',\n",
        "        batch_size=32,\n",
        "        target_size=[224,224],\n",
        "        class_mode='binary',\n",
        "        shuffle=True,\n",
        "        seed=42)\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "        validation_path,\n",
        "        color_mode='rgb',\n",
        "        batch_size=32,\n",
        "        target_size=[224,224],\n",
        "        class_mode='binary',\n",
        "        shuffle=True,\n",
        "        seed=42)\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "        test_path,\n",
        "        target_size=[224,224],\n",
        "        color_mode='rgb',\n",
        "        class_mode='binary',\n",
        "        shuffle=False,\n",
        "        batch_size = 1,\n",
        "        seed=42)\n",
        "print(train_generator.filenames)\n",
        "\n",
        "#Imprime una imagen 5 veces aplicando data augmentation\n",
        "augmented_images = [train_generator[2][0][0] for i in range(5)]\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5)\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(preprocessing_image.array_to_img(img))\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "plotImages(augmented_images)\n",
        "\n",
        "\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VAL=validation_generator.n//validation_generator.batch_size\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNI8vVK9_4si",
        "colab_type": "text"
      },
      "source": [
        "#PESOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrcpcj4wBGu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PESOS \n",
        "\n",
        "#Calculo de los pesos para el desbalanceo de clases\n",
        "melanoma_weight = 374/1746\n",
        "nevus_weight = 1372/1746\n",
        "class_weight = {1: nevus_weight,\n",
        "                0: melanoma_weight}\n",
        "\n",
        "#Descarga pesos ImageNet\n",
        "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
        "'releases/download/v0.1/'\n",
        "'vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "\n",
        "Imagenet_weights = utils.get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',WEIGHTS_PATH,cache_subdir='models',file_hash='64373286793e3c8b2b4e3219cbf3544b')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIXCJwTaAi1k",
        "colab_type": "text"
      },
      "source": [
        "#**MODELOS**\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cIcS0cXBO55",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# METRICS\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tzrEc9O85r7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Funciones\n",
        "def obtainFnFpTnTp(y_true,y_pred):\n",
        "    y_pred = K.round(K.clip(y_pred, 0, 1))\n",
        "    neg_y_true = 1 - y_true\n",
        "    neg_y_pred = 1 - y_pred\n",
        "    fp = K.sum(neg_y_true * y_pred)\n",
        "    tp = K.sum(y_true * y_pred)\n",
        "    tn = K.sum(neg_y_true * neg_y_pred)\n",
        "    fn = K.sum( y_true * neg_y_pred)\n",
        "    return fp,tp,fn,tn\n",
        "    \n",
        "def precision(y_true, y_pred):\n",
        "  fp,tp,fn,tn = obtainFnFpTnTp(y_true,y_pred)\n",
        "  precision = tp/(tp+fp + K.epsilon())\n",
        "  return precision\n",
        "\n",
        "def sensibilidad(y_true, y_pred):\n",
        "  fp,tp,fn,tn = obtainFnFpTnTp(y_true,y_pred)\n",
        "  sensibilidad = tp/(tp+fn + K.epsilon())\n",
        "  return sensibilidad\n",
        "\n",
        "def especifidad(y_true,y_pred):\n",
        "  print(y_true)\n",
        "  print(y_pred)\n",
        "  fp,tp,fn,tn = obtainFnFpTnTp(y_true,y_pred)\n",
        "  especifidad = tn/(tn + fp + K.epsilon())\n",
        "  return especifidad\n",
        "\n",
        "def aucs(y_true, y_pred):\n",
        "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
        "    return auc\n",
        "\n",
        "def roc_curve_and_score(y_test, pred_proba):\n",
        "    fpr, tpr, _ = roc_curve(y_test.ravel(), pred_proba.ravel())\n",
        "    roc_auc = roc_auc_score(y_test.ravel(), pred_proba.ravel())\n",
        "    return fpr, tpr, roc_auc"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Er1sUs5_ygp6"
      },
      "source": [
        "# MODELO VGG-16 + módulos de atención\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YZQ0g904T2D9",
        "colab": {}
      },
      "source": [
        "### VGG16 CON LOS MECANISMOS DE ATENCION\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "img_input = Input(shape=[224,224,3], name=\"input_1\")\n",
        "x = (Conv2D(64,(3,3), padding='same', name=\"block1_conv1\")) (img_input)\n",
        "x = (BatchNormalization(name='block1_bn1'.format(1, 1)))(x)\n",
        "x = (Activation('relu', name='block1_act1'.format(1, 1)))(x)\n",
        "\n",
        "x = (Conv2D(64,(3,3), padding='same', name=\"block1_conv2\"))(x)\n",
        "x = (BatchNormalization(name='block1_bn2'.format(1, 2)))(x)\n",
        "x = (Activation('relu', name='block1_act2'.format(1, 2)))(x)\n",
        "\n",
        "\n",
        "x = (MaxPooling2D((2,2),strides=(2,2), name=\"block1_pool\"))(x)\n",
        "\n",
        "x= (Conv2D(128,(3,3), padding='same', name=\"block2_conv1\"))(x)\n",
        "x = (BatchNormalization(name='block2_bn1'.format(2, 1)))(x)\n",
        "x = (Activation('relu', name='block2_act1'.format(2, 1)))(x)\n",
        "\n",
        "\n",
        "x= (Conv2D(128,(3,3), padding='same', name=\"block2_conv2\"))(x)\n",
        "x = (BatchNormalization(name='block2_bn2'.format(2, 2)))(x)\n",
        "x = (Activation('relu', name='block2_act2'.format(2, 2)))(x)\n",
        "\n",
        "\n",
        "x = (MaxPooling2D((2,2),strides=(2,2), name=\"block2_pool\"))(x)\n",
        "\n",
        "x= (Conv2D(256,(3,3), padding='same', name=\"block3_conv1\"))(x)\n",
        "x = (BatchNormalization(name='block3_bn1'.format(3, 1)))(x)\n",
        "x = (Activation('relu', name='block3_act1'.format(3, 1)))(x)\n",
        "\n",
        "\n",
        "x= (Conv2D(256,(3,3), padding='same', name=\"block3_conv2\"))(x)\n",
        "x = (BatchNormalization(name='block3_bn2'.format(3, 2)))(x)\n",
        "x = (Activation('relu', name='block3_act2'.format(3, 2)))(x)\n",
        "\n",
        "\n",
        "x= (Conv2D(256,(3,3), padding='same', name=\"block3_conv3\"))(x)\n",
        "x = (BatchNormalization(name='block3_bn3'.format(3, 3)))(x)\n",
        "x = (Activation('relu', name='block3_act3'.format(3, 3)))(x)\n",
        "\n",
        "pool_3 = (MaxPooling2D((2,2),strides=(2,2), name=\"block3_pool\"))(x)\n",
        "\n",
        "x= (Conv2D(512,(3,3), padding='same', name=\"block4_conv1\"))(pool_3)\n",
        "x = (BatchNormalization(name='block4_bn1'.format(4, 1)))(x)\n",
        "x = (Activation('relu', name='block4_act1'.format(4, 1)))(x)\n",
        "\n",
        "\n",
        "x= (Conv2D(512,(3,3), padding='same', name=\"block4_conv2\"))(x)\n",
        "x = (BatchNormalization(name='block4_bn2'.format(4, 2)))(x)\n",
        "x = (Activation('relu', name='block4_act2'.format(4, 2)))(x)\n",
        "\n",
        "\n",
        "x = (Conv2D(512,(3,3), padding='same', name=\"block4_conv3\"))(x)\n",
        "x = (BatchNormalization(name='block4_bn3'.format(4, 3)))(x)\n",
        "x = (Activation('relu', name='block4_act3'.format(4, 3)))(x)\n",
        "\n",
        "\n",
        "pool_4 = (MaxPooling2D((2,2),strides=(2,2), name=\"block4_pool\"))(x)\n",
        "\n",
        "x= (Conv2D(512,(3,3), padding='same', name=\"block5_conv1\"))(pool_4)\n",
        "x = (BatchNormalization(name='block5_bn1'.format(5, 1)))(x)\n",
        "x = (Activation('relu', name='block5_act1'.format(5, 1)))(x)\n",
        "\n",
        "x= (Conv2D(512,(3,3), padding='same', name=\"block5_conv2\"))(x)\n",
        "x = (BatchNormalization(name='block5_bn2'.format(5, 2)))(x)\n",
        "x = (Activation('relu', name='block5_act2'.format(5, 2)))(x)\n",
        "\n",
        "\n",
        "x= (Conv2D(512,(3,3), padding='same',name=\"block5_conv3\"))(x)\n",
        "x = (BatchNormalization(name='block5_bn3'.format(5,3)))(x)\n",
        "x = (Activation('relu', name='block5_act3'.format(5, 3)))(x)\n",
        "\n",
        "\n",
        "pool_5 = (MaxPooling2D((2,2),strides=(2,2), name=\"block5_pool\"))(x)\n",
        "\n",
        "## MODULOS DE ATENCION\n",
        "\n",
        "#pool3\n",
        "wf3 =(Conv2D(256,(3,3), activation = 'relu', padding='same', name=\"conv2d_13\"))(pool_3)\n",
        "wg3 = (Conv2D(256,(3,3), activation = 'relu', padding='same', name=\"conv2d_14\"))(pool_5)\n",
        "wg3 = (UpSampling2D(size = 4, name=\"up_sampling2d\" ))(wg3)\n",
        "\n",
        "added3 = Add(name='add')([wf3, wg3])\n",
        "Relu3 = (Activation('relu', name='MAP1_relu'.format(1, 1)))(added3)\n",
        "A3 = (Conv2D(1,(3,3), padding='same', name=\"conv2d_15\"))(Relu3)\n",
        "A3 = (Activation('sigmoid', name='MAP1_sigmoid'.format(1, 1)))(A3)\n",
        "\n",
        "multiply3 = Multiply(name='multiply')([A3, pool_3])\n",
        "attention_1 = multiply3\n",
        "\n",
        "#pool_4\n",
        "wf4 =(Conv2D(256,(3,3), activation = 'relu', padding='same', name=\"conv2d_16\"))(pool_4)\n",
        "wg4 = (Conv2D(256,(3,3), activation = 'relu', padding='same',name=\"conv2d_17\"))(pool_5)\n",
        "wg4 = (UpSampling2D(size = 2, name=\"up_sampling2d_1\"))(wg4)\n",
        "\n",
        "added4 = Add(name=\"add_1\")([wf4, wg4])\n",
        "Relu4 = (Activation('relu', name='MAP2_relu'.format(1, 1)))(added4)\n",
        "A4 = (Conv2D(1,(3,3), padding='same', name=\"conv2d_18\"))(Relu4)\n",
        "A4 = (Activation('sigmoid', name='MAP2_sigmoid'.format(1, 1)))(A4)\n",
        "\n",
        "multiply4 = Multiply(name=\"multiply_1\")([A4, pool_4])\n",
        "attention_2 = multiply4\n",
        "\n",
        "GlobalAverageAtention1 = GlobalAveragePooling2D(name=\"global_average_pooling2d\")(attention_1)\n",
        "GlobalAverageAtention2 = GlobalAveragePooling2D(name=\"global_average_pooling2d_1\")(attention_2)\n",
        "GlobalAveragePool5 = GlobalAveragePooling2D(name=\"global_average_pooling2d_2\")(pool_5)\n",
        "Concatenate1 = Concatenate(axis=1, name=\"concatenate\")([GlobalAverageAtention1, GlobalAverageAtention2])\n",
        "feature_vector = Concatenate(axis=1, name=\"concatenate_1\")([Concatenate1, GlobalAveragePool5])\n",
        "out = Dense(1, activation = 'sigmoid', name=\"dense\")(feature_vector)\n",
        "\n",
        "trained_model = Model(inputs = [img_input], outputs = [out])\n",
        "trained_model.load_weights(Imagenet_weights,by_name=True)\n",
        "trained_model.summary()\n",
        "plot_model(trained_model, to_file='model.png',show_shapes=True,show_layer_names=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_D66_l8A5e8",
        "colab_type": "text"
      },
      "source": [
        "#**ENTRENAMIENTO**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnA7xU_TTspE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d0ab2c77-ff5a-428b-b395-f8db75e53090"
      },
      "source": [
        "# FUNCIONES\n",
        "\n",
        "# Learning rate variable\n",
        "def scheduler(epoch,lr):\n",
        "  if epoch%10 == 0:\n",
        "    if(epoch==0):\n",
        "      print(\"epoca:\", epoch)\n",
        "      print(lr)\n",
        "      return lr\n",
        "\n",
        "    print(\"epoca:\", epoch)\n",
        "    print(lr)\n",
        "    return lr/10\n",
        "  else:\n",
        "    print(\"epoca:\", epoch)\n",
        "    print(lr)\n",
        "    return lr\n",
        "\n",
        "learningRateScheduler = LearningRateScheduler(scheduler)\n",
        "\n",
        "# Focal_loss\n",
        "def focal_loss(gamma=2., alpha=.25):\n",
        "  def focal_loss_fixed(y_true, y_pred):\n",
        "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "    return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
        "  return focal_loss_fixed\n",
        "\n",
        "# optimizadores\n",
        "adam = Adam(learning_rate=0.00001, amsgrad=False)\n",
        "\n",
        "#Earlystopping\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode =\"min\", patience=10)\n",
        "\n",
        "#checkpoint\n",
        "checkpoint = ModelCheckpoint('weights/Adam/Focal_loss/Checkpoint.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min', period=1, save_weights_only=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uud3YryXOOto",
        "colab_type": "text"
      },
      "source": [
        "#ATTENTION_MODEL\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GkUAa3Na0gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16Gap.compile(loss=[focal_loss(gamma=2., alpha=.25)], optimizer=adam, metrics=['acc',precision,especifidad,sensibilidad,AUC()])\n",
        "history = vgg16Gap.fit_generator(generator=train_generator,\n",
        "                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "                              epochs=50,\n",
        "                              class_weight=class_weight,\n",
        "                              validation_data=validation_generator,\n",
        "                              callbacks=[learningRateScheduler, checkpoint],\n",
        "                              validation_steps = STEP_SIZE_VAL)\n",
        "vgg16Gap.save_weights('weights/Adam/Focal_loss/AttnMelCNN-weights.h5')2l\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttwZirpUBySy",
        "colab_type": "text"
      },
      "source": [
        "#**RESULTADOS**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7MT4pf9DLGX",
        "colab_type": "text"
      },
      "source": [
        "#CURVA ROC Y MEDIDAS DE EVALUACION "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2A68Zs3ba5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## OBTENCION CURVA ROC Y AUC \n",
        "\n",
        "trained_model.load_weights(\"weights/Adam/Focal_loss/definitivos.h5\")\n",
        "\n",
        "test_generator.reset()\n",
        "pred=trained_model.predict_generator(test_generator,\n",
        "steps=STEP_SIZE_TEST,\n",
        "verbose=1)\n",
        "\n",
        "# Curva ROC y AUC\n",
        "fpr,tpr,auc = roc_curve_and_score(test_generator.labels,pred)\n",
        "auc_test = auc\n",
        "especifidad_test = especifidad(test_generator.labels, pred)\n",
        "AP_test = average_precision_score(test_generator.labels, pred)\n",
        "\n",
        "\n",
        "def plot_roc_curve(fpr,tpr): \n",
        "  plt.plot(fpr,tpr) \n",
        "  plt.axis([0,1,0,1]) \n",
        "  plt.xlabel('False Positive Rate') \n",
        "  plt.ylabel('True Positive Rate') \n",
        "  plt.show()    \n",
        "  \n",
        "plot_roc_curve (fpr,tpr)\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#Cálculo del número de aciertos \n",
        "aciertos=0\n",
        "aciertos_verdaderos=0;\n",
        "for x in range(len(test_generator.labels)):\n",
        "  if(K.round(pred[x]) == test_generator.labels[x]):\n",
        "    aciertos = aciertos+1\n",
        "    if(test_generator.labels[x] == 1):\n",
        "      aciertos_verdaderos = aciertos_verdaderos+1\n",
        "\n",
        "print(\"---------------ESTADISTICAS---------------\")\n",
        "print(\"Aciertos totales: \",aciertos)\n",
        "print(\"De 117 melanomas ha acertado: \", aciertos_verdaderos)\n",
        "print(\"De 393 nevus ha acertado: \", aciertos - aciertos_verdaderos)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY8ReoP6B3Nh",
        "colab_type": "text"
      },
      "source": [
        "#MAPAS DE ATENCIÓN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilr80c1lflmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A partir del modelo recien entrenado, \"creo\" otro modelo asignandole las posiciones de memoria reservadas con los pesdel os al entrenarlo\n",
        "\n",
        "attention_model_1 = Model(inputs=trained_model.input, outputs=[trained_model.layers[57].output,trained_model.layers[58].output,trained_model.layers[-1].output])\n",
        "\n",
        "test_generator.reset()\n",
        "_prediction=attention_model_1.predict_generator(test_generator,steps=STEP_SIZE_TEST,\n",
        "verbose=1)\n",
        "\n",
        "MAP_1 =  _prediction[0]\n",
        "MAP_2 = _prediction[1]\n",
        "predictions = _prediction[2]\n",
        "  \n",
        "x_test=test_generator.filepaths\n",
        "\n",
        "for i in range(5):\n",
        "  figure = plt.figure()\n",
        "  figure.add_subplot(1,3,1)\n",
        "  image_ = cv2.imread(x_test[i])\n",
        "  image = cv2.cvtColor(image_, cv2.COLOR_BGR2RGB)\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  figure.add_subplot(1,3,2)\n",
        "  plt.imshow(preprocessing_image.array_to_img(st.resize(np.array(MAP_1[i]),(image_.shape[0],image_.shape[1],1))))\n",
        "  figure.add_subplot(1,3,3)\n",
        "  plt.imshow(preprocessing_image.array_to_img(st.resize(np.array(MAP_2[i]),(image_.shape[0],image_.shape[1],1))))\n",
        "  plt.show()\n",
        "  print(\"La prediccion es: \", K.round(predictions[i]))\n",
        "  print(\"en realidad es: \", K.round(test_generator.labels[i]))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3wYVaK0ov9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#obtencion MAP\n",
        "output_layer_ = trained_model.get_layer(name = \"dense\").output\n",
        "attention = trained_model.get_layer(name = \"MAP1_sigmoid\").output\n",
        "attention_ = trained_model.get_layer(name = \"MAP2_sigmoid\").output\n",
        "Attention_extraction_model1 = Model(inputs=trained_model.input, outputs=[attention, attention_,output_layer_])\n",
        "\n",
        "Attention_extraction_model1.load_weights('weights/Adam/Focal_loss/definitivos.h5', by_name=True)\n",
        "\n",
        "test_generator.reset()\n",
        "_prediction=Attention_extraction_model1.predict_generator(test_generator,steps=STEP_SIZE_TEST,\n",
        "verbose=1)\n",
        "\n",
        "MAP_1 =  _prediction[0]\n",
        "MAP_2 = _prediction[1]\n",
        "predictions = _prediction[2]\n",
        "\n",
        "x_test=test_generator.filepaths\n",
        "for i in range(5):\n",
        "  figure = plt.figure()\n",
        "  figure.add_subplot(1,3,1)\n",
        "  image_ = cv2.imread(x_test[i])\n",
        "  image = cv2.cvtColor(image_, cv2.COLOR_BGR2RGB)\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  figure.add_subplot(1,3,2)\n",
        "  plt.imshow(preprocessing_image.array_to_img(st.resize(np.array(MAP_1[i]),(image_.shape[0],image_.shape[1],1))))\n",
        "  figure.add_subplot(1,3,3)\n",
        "  plt.imshow(preprocessing_image.array_to_img(st.resize(np.array(MAP_2[i]),(image_.shape[0],image_.shape[1],1))))\n",
        "  plt.show()\n",
        "  print(\"La prediccion es: \", K.round(predictions[i]))\n",
        "  print(\"en realidad es: \", K.round(test_generator.labels[i]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4IxK5mLczOm",
        "colab_type": "text"
      },
      "source": [
        "# ANALISIS \n",
        "\n",
        "---\n",
        "\n",
        "PARTE 1 - **ESTRUCTURAS**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OztqlwpwwS0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "#FUNCIONES\n",
        "\n",
        "#Decodifica la mascara de superpixeles\n",
        "def decodeSuperpixelIndex(rgbValue):\n",
        "    return (rgbValue[..., 0].astype(np.uint64)) + (rgbValue[..., 1].astype(np.uint64) << np.uint64(8)) + (rgbValue[..., 2].astype(np.uint64) << np.uint64(16))\n",
        "\n",
        "#Genera la/las mascara/s de estructura/s de una imagen \n",
        "def getStructureMasksFromImage(imageName):\n",
        "  test_path = dataset_path + 'test' + os.sep\n",
        "  superpixel_path = test_path +  'ISIC-2017_Test_v2_Data' + os.sep + imageName + \"_superpixels.png\"\n",
        "  json_path = json_dirname + os.sep + 'test' + os.sep + 'ISIC-2017_Test_v2_Part2_GroundTruth' + os.sep + imageName + \"_features.json\"\n",
        "  output_base_path = os.path.join(os.getcwd(),'imagenes_y_etiquetas/superpixels/test')\n",
        "\n",
        "  print(json_path)\n",
        "\n",
        "  json = readJson(json_path)\n",
        "  superpixel_mask_img = preprocessing_image.load_img(superpixel_path)\n",
        "  superpixel_mask_array = preprocessing_image.img_to_array(superpixel_mask_img)\n",
        "  createDir(output_base_path + os.sep + imageName)\n",
        "  keys = getKeysFormJson(json)\n",
        "  complete_mask = np.zeros(crop(superpixel_mask_array).shape)\n",
        "  for key in keys:\n",
        "    structure = key\n",
        "    superpixel_mask_decoded = np.zeros(superpixel_mask_array.shape)\n",
        "    for y in range(superpixel_mask_array.shape[0]):\n",
        "      for x in range(superpixel_mask_array.shape[1]):\n",
        "        pixel = decodeSuperpixelIndex(superpixel_mask_array[y,x,:])\n",
        "        superpixel_mask_decoded[y,x,:]=pixel\n",
        "\n",
        "    structure_mask = getOneStructureMask(json,structure,superpixel_mask_decoded)\n",
        "    output_superpixel_mask_path = output_base_path + os.sep + imageName + os.sep + imageName + \"_\" + structure + \".png\"\n",
        "    preprocessing_image.save_img(output_superpixel_mask_path, structure_mask)\n",
        "    complete_mask = get_mask_completed(key,structure_mask,complete_mask)\n",
        "\n",
        "  percentage_structure = getPercentageStructures(complete_mask)\n",
        "  output_superpixel_complete_mask_path = output_base_path + os.sep + imageName + os.sep + imageName  + \".png\"\n",
        "  preprocessing_image.save_img(output_superpixel_complete_mask_path, complete_mask)\n",
        "  return percentage_structure\n",
        "\n",
        "#Genera la mascara de una estructura \n",
        "def getOneStructureMask(json, key, superpixel_mask_decoded_aux):\n",
        "  data = getDataFromKey(json, key)\n",
        "  for j in range(len(data)): \n",
        "    value = 0\n",
        "    if(np.array(data)[j] == 1):\n",
        "      value = 1\n",
        "    superpixel_mask_decoded_aux[superpixel_mask_decoded_aux==j] = value\n",
        "  return crop(superpixel_mask_decoded_aux)\n",
        "\n",
        "#Genera la máscara conjunta de todas las estructuras\n",
        "def get_mask_completed(structure, structure_mask,complete_mask):\n",
        "  structures= [\"pigment_network\",\"negative_network\",\"milia_like_cyst\",\"streaks\"]\n",
        "  complete_mask[structure_mask==1] = (structures.index(structure)+1)/4\n",
        "  return complete_mask\n",
        "\n",
        "#Obtiene los porcentajes de cada estructura sobre la imagen completa\n",
        "def getPercentageStructures(complete_mask):\n",
        "  percentages_structures = []\n",
        "  structures= [\"skin\",\"pigment_network\",\"negative_network\",\"milia_like_cyst\",\"streaks\"]\n",
        "  structures_values = [0,0.25,0.5,0.75,1]\n",
        "\n",
        "  for i in range(len(structures)):\n",
        "    structure_pixels=np.where(complete_mask==structures_values[i], 1., 0.)\n",
        "    percentage = (np.sum(structure_pixels)/(complete_mask.shape[0]*complete_mask.shape[1]*complete_mask.shape[2]))*100\n",
        "    percentages_structures.append(percentage)\n",
        "  print(\"porcentages: \", percentages_structures)\n",
        "  return percentages_structures\n",
        "\n",
        "#Crea un directorio\n",
        "def createDir(dirPath):\n",
        "  if not os.path.exists(dirPath):\n",
        "    os.makedirs(dirPath)\n",
        "\n",
        "#Lee un archivo .json\n",
        "def readJson(jsonFile_path):\n",
        "  with open(jsonFile_path, 'r') as fi:\n",
        "    data = json.load(fi)\n",
        "  return data\n",
        "\n",
        "#Obtiene las claves de un archivo json\n",
        "def getKeysFormJson(jsonFile):\n",
        "  return jsonFile.keys()\n",
        "\n",
        "#Obtiene el array de datos perteneciente a una clave de un .json\n",
        "def getDataFromKey(data,key):\n",
        "  return data[key]\n",
        "\n",
        "# EXPORTAR A EXCEL LA INFORMACION SOBRE % DE PIXELES DE CADA ESTRUCTURA EN CADA IMAGEN\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "def saveDataExcel(i,image_names,melanoma,s0,s1,s2,s3,s4):\n",
        "  data = {'image': image_names,'melanoma': melanoma,'skin': s0,'pigment_network': s1,'negative_network': s2,'milia_like_cyst': s3,'streaks': s4}\n",
        "  df = pd.DataFrame(data, columns = ['image', 'melanoma', 'skin', 'pigment_network', 'negative_network','milia_like_cyst','streaks'])\n",
        "  path = 'imagenes_y_etiquetas/superpixels/test/structures%s.xlsx' % (i)\n",
        "  excel_path = os.path.join(os.getcwd(),path)\n",
        "  df.to_excel(excel_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iknDm5uVoMjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_names = test_generator.filenames\n",
        "s0 = []\n",
        "s1 = []\n",
        "s2 = []\n",
        "s3 = []\n",
        "s4 = []\n",
        "images = []\n",
        "melanoma = []\n",
        "\n",
        "for i in range(len(image_names)):\n",
        "  print(i)\n",
        "  image = image_names[i]\n",
        "  print(image)\n",
        "  pos = image_names.index(image)\n",
        "  porcentages = getStructureMasksFromImage(image.split(\"/\")[1].split(\".\")[0])\n",
        "  if(test_generator.labels[::-1][pos]==1):\n",
        "    melanoma.append(1)\n",
        "  else: \n",
        "    melanoma.append(0)\n",
        "  images.append(image.split(\"/\")[1].split(\".\")[0])\n",
        "  s0.append(porcentages[0])\n",
        "  s1.append(porcentages[1])\n",
        "  s2.append(porcentages[2])\n",
        "  s3.append(porcentages[3])\n",
        "  s4.append(porcentages[4])\n",
        "  print(images)\n",
        "  print(melanoma)\n",
        "  print(s0)\n",
        "  print(s1)\n",
        "  print(s2)\n",
        "  print(s3)\n",
        "  print(s4)\n",
        "\n",
        "  if(i%10==0):\n",
        "    if(i==0):\n",
        "      print(\"0\")\n",
        "    else:\n",
        "      #saveDataExcel(i,images,melanoma,s0,s1,s2,s3,s4)\n",
        "      s0 = []\n",
        "      s1 = []\n",
        "      s2 = []\n",
        "      s3 = []\n",
        "      s4 = []\n",
        "      images = []\n",
        "      melanoma = []\n",
        "\n",
        "print(\"image_names\",image_names)\n",
        "print(\"melanoma\",melanoma)\n",
        "print(\"s0\",s0)\n",
        "print(\"s1\",s1)\n",
        "print(\"s2\",s2)\n",
        "print(\"s3\",s3)\n",
        "print(\"s4\",s4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0bbOgEaQP-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mascara de estructuras incluyendo la lesion\n",
        "def invertir(array):\n",
        "  return abs(array-1)\n",
        "\n",
        "def saveLesionMasc(masc, imageName, masc_structure_path):\n",
        "  path = masc_structure_path + imageName + os.sep + imageName + \"_lesion\" + \".png\"\n",
        "  print(path)\n",
        "  preprocessing_image.save_img(path, masc)\n",
        "  return\n",
        "def saveExcel(lesion, skin):\n",
        "  data = {'lesion': lesion,'skin': skin}\n",
        "  df = pd.DataFrame(data, columns = ['lesion', 'skin'])\n",
        "  path = 'imagenes_y_etiquetas/superpixels/structures_test_lesion%s.xlsx' % (i)\n",
        "  excel_path = os.path.join(os.getcwd(),path)\n",
        "  df.to_excel(excel_path)\n",
        "  return\n",
        "\n",
        "def getLesionPorcentaje(imageName):\n",
        "  test_path = os.path.join(os.getcwd(),'imagenes_y_etiquetas/part 1/test/')\n",
        "  masc_path = test_path +  \"ISIC-2017_Test_v2_Part1_GroundTruth\" + os.sep + imageName + \"_segmentation.png\"\n",
        "  masc_structure_path = os.path.join(os.getcwd(),'imagenes_y_etiquetas/superpixels/test/')\n",
        "\n",
        "  masc = crop(preprocessing_image.img_to_array(preprocessing_image.load_img(masc_path)))\n",
        "  plt.imshow(preprocessing_image.array_to_img(masc))\n",
        "  plt.imshow()\n",
        "  structures = [\"pigment_network\",\"negative_network\",\"milia_like_cyst\",\"streaks\"]\n",
        "\n",
        "  for structure in structures:\n",
        "    masc_structure = preprocessing_image.img_to_array(preprocessing_image.load_img(masc_structure_path + imageName + os.sep + imageName + \"_\" + structure + \".png\"))/255\n",
        "    masc[masc_structure == 1] = 0\n",
        "    masc_structure = []\n",
        "  saveLesionMasc(masc, imageName, masc_structure_path)\n",
        "\n",
        "  porcentaje_lesion = (np.sum(masc/255)/(masc.shape[0] * masc.shape[1] * masc.shape[2]))*100\n",
        "  porcentaje_skin = (np.sum(invertir(masc/255))/(masc.shape[0] * masc.shape[1] * masc.shape[2]))*100\n",
        "\n",
        "  return porcentaje_lesion, porcentaje_skin\n",
        "\n",
        "test_gener = test_generator\n",
        "image_names = [\"a-nevus/ISIC_0016036\"]\n",
        "lesion = []\n",
        "skin = [] \n",
        "\n",
        "for image_name in image_names:\n",
        "  i = image_names.index(image_name)\n",
        "  print(\"image %s: %s\" %(i,image_name))\n",
        "  p_lesion, p_skin = getLesionPorcentaje(image_name.split(\"/\")[1].split(\".\")[0])\n",
        "  print(p_lesion)\n",
        "  print(p_skin)\n",
        "  lesion.append(p_lesion)\n",
        "  skin.append(p_skin)\n",
        "\n",
        "  if((i%len(image_names)==0)):\n",
        "    saveExcel(lesion, skin)\n",
        "    lesion = []\n",
        "    skin = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em332WuloaF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Obtener la mascara totla con todas las estructuras incluida la lesion\n",
        "def changestructurecomplete(image_name):\n",
        "  structures= [\"lesion\",\"pigment_network\",\"negative_network\",\"milia_like_cyst\",\"streaks\"]\n",
        "  path = os.path.join(os.getcwd(),'imagenes_y_etiquetas/superpixels/test')\n",
        "  img_masc_path = path + os.sep + image_name + os.sep + image_name + \".png\"\n",
        "  img_masc = preprocessing_image.img_to_array(preprocessing_image.load_img(img_masc_path))\n",
        "\n",
        "  complete_mask = np.zeros(img_masc.shape)\n",
        "  for structure in structures:\n",
        "    img_structure_masc_path = path + os.sep + image_name + os.sep + image_name + \"_\" + structure + \".png\"\n",
        "    img_structure_masc = preprocessing_image.img_to_array(preprocessing_image.load_img(img_structure_masc_path))\n",
        "    complete_mask[img_structure_masc==255] = (structures.index(structure)+1)/5\n",
        "  preprocessing_image.save_img(img_masc_path, complete_mask)\n",
        "\n",
        "for image_name in image_names:\n",
        "  name = image_name.split(\"/\")[1].split(\".\")[0]\n",
        "  changestructurecomplete(name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov7glHS-w9x0",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "PARTE 2 - **ATENCION** ¿A que estructuras atiende más la red?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh53RtdEGlif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FUNCIONES\n",
        "\n",
        "#Recupera la mascara de estructuras correspondiente a una imagen y una estructura \n",
        "def getStructureMask(image_name, structure):\n",
        "  path = os.path.join(os.getcwd(),'imagenes_y_etiquetas/superpixels/test')\n",
        "  if(structure == \"skin\"):\n",
        "    structure_mask_path = path + os.sep + image_name + os.sep + image_name + \".png\"\n",
        "  else:\n",
        "    structure_mask_path = path + os.sep + image_name + os.sep + image_name + \"_\" + structure + \".png\"\n",
        "  structure_mask = preprocessing_image.load_img(structure_mask_path)\n",
        "  structure_mask_array = preprocessing_image.img_to_array(structure_mask)\n",
        "  return structure_mask_array\n",
        "\n",
        "#Redimensiona el mapa de atención espacial\n",
        "def getResizedMap(attn_map, shape):\n",
        "  map_resized= st.resize(attn_map, shape)\n",
        "  plt.imshow(map_resized)\n",
        "  plt.show()\n",
        "  return st.resize(attn_map, shape)\n",
        "\n",
        "#Calcula las probabilidades de atención dada una estructura\n",
        "def getPorcentajeStructure(image_name, structure, mask, MAP):\n",
        "  # Calculo p_att (atención)\n",
        "  p_att = np.sum(MAP) / np.size(MAP) # Promedio de atención, a nivel de píxel.\n",
        "  p_non_att=np.sum(1-MAP) / np.size(1-MAP)\n",
        "\n",
        "  # Calculo p_si_given_att (condicional estructura dada atención)\n",
        "  if(np.sum(MAP)==0):\n",
        "    MAP_normalized = np.zeros(MAP.shape)\n",
        "  else:\n",
        "    MAP_normalized = MAP / np.sum(MAP) \n",
        "  p_si = np.sum(mask==1) / np.size(mask)\n",
        "  p_si_given_att = np.sum(np.multiply(((MAP)/np.sum(MAP)), (mask==1)))\n",
        "  p_si_given_non_att = np.sum(np.multiply(((1-MAP)/np.sum(1-MAP)),(mask==1)))\n",
        "\n",
        "  # Calculo p_si (estructura)\n",
        "  p_si = np.sum(mask) / np.size(mask)\n",
        "\n",
        "  # Finalmente, calculo p_att_given_si\n",
        "  p_attn_given_si =(p_si_given_att*p_att)/(p_si + np.finfo(float).eps)\n",
        "  p_non_att_given_si= (p_si_given_non_att*p_non_att)/(p_si+np.finfo(float).eps)\n",
        "  return p_attn_given_si\n",
        "\n",
        "def saveDataExcel(map,i,image_names,melanoma,s0,s1,s2,s3,s4,lesion):\n",
        "  data = {'image': image_names,'melanoma': melanoma,'skin': s0,'lesion':lesion, 'pigment_network': s1,'negative_network': s2,'milia_like_cyst': s3,'streaks': s4}\n",
        "  df = pd.DataFrame(data, columns = ['image', 'melanoma', 'skin', 'lesion','pigment_network', 'negative_network','milia_like_cyst','streaks'])\n",
        "  path = 'imagenes_y_etiquetas/attention/test/attention_ttest_%s_%s.xlsx' % (map, i)\n",
        "  excel_path = os.path.join(os.getcwd(),path)\n",
        "  df.to_excel(excel_path)\n",
        "\n",
        "def vaciarArrays():\n",
        "  imag_names = []\n",
        "  melanoma = []\n",
        "  S0_1 = []\n",
        "  S0_2 = []\n",
        "  S1_1 = []\n",
        "  S1_2 = []\n",
        "  S2_1 = []\n",
        "  S2_2 = []\n",
        "  S3_1 = []\n",
        "  S3_2 = []\n",
        "  S4_1 = []\n",
        "  S4_2 = []\n",
        "  lesion_1=[]\n",
        "  lesion_2=[]\n",
        "  return imag_names,melanoma,S0_1,S0_2,S1_1,S1_2,S2_1,S2_2,S3_1,S3_2,S4_1,S4_2, lesion_1,lesion_2\n",
        "\n",
        "def getAttn(label,name, attn_map_1, attn_map_2, structures):\n",
        "  attn_2_porcentajes=[]\n",
        "  attn_1_porcentajes=[]\n",
        "  for structure in structures:\n",
        "    print(\"---- %s ----\" % (structure))\n",
        "    mask = getStructureMask(name,structure)\n",
        "    if(structure == \"skin\"):\n",
        "      mask = np.where(mask==0, 1,0)\n",
        "    \n",
        "    if(np.sum(mask)!= 0):\n",
        "      mask = mask / np.max(mask)\n",
        "    shape = mask.shape\n",
        "    MAP_1_resized =  getResizedMap(attn_map_1,shape)\n",
        "    MAP_2_resized=  getResizedMap(attn_map_2,shape)\n",
        "    porcentaje_1 = getPorcentajeStructure(name, structure, mask,MAP_1_resized)\n",
        "    attn_1_porcentajes.append(porcentaje_1)\n",
        "    porcentaje_2 = getPorcentajeStructure(name, structure, mask,MAP_2_resized)\n",
        "    attn_2_porcentajes.append(porcentaje_2)\n",
        "  \n",
        "  return attn_1_porcentajes, attn_2_porcentajes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk670PV-eMoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "image_labels =[]\n",
        "image_names = []\n",
        "train_generator_ = test_generator\n",
        "image_names = train_generator_.filenames\n",
        "image_labels = train_generator_.labels\n",
        "structures = [\"skin\", \"lesion\", \"pigment_network\",\"negative_network\",\"milia_like_cyst\",\"streaks\"]\n",
        "attn_2_porcentajes = []\n",
        "attn_1_porcentajes = []\n",
        "imag_names,melanoma,S0_1,S0_2,S1_1,S1_2,S2_1,S2_2,S3_1,S3_2,S4_1,S4_2, lesion_1,lesion_2 = vaciarArrays()\n",
        "\n",
        "for image_name in image_names_:\n",
        "  i=image_names.index(image_name)\n",
        "  name = image_names[i].split(\"/\")[1].split(\".\")[0]\n",
        "  label = image_labels[i]\n",
        "  attn_map_1 = MAP_1[i,:,:,:]\n",
        "  attn_map_2 = MAP_2[i,:,:,:]\n",
        "  attn_1_porcentajes, attn_2_porcentajes = getAttn(label,name, attn_map_1, attn_map_2, structures)\n",
        "  imag_names.append(name)\n",
        "  melanoma.append(label)\n",
        "\n",
        "  S0_1.append(attn_1_porcentajes[0])\n",
        "  lesion_1.append(attn_1_porcentajes[1])\n",
        "  S1_1.append(attn_1_porcentajes[2])\n",
        "  S2_1.append(attn_1_porcentajes[3])\n",
        "  S3_1.append(attn_1_porcentajes[4])\n",
        "  S4_1.append(attn_1_porcentajes[5])\n",
        "  S0_2.append(attn_2_porcentajes[0])\n",
        "  lesion_2.append(attn_2_porcentajes[1])\n",
        "  S1_2.append(attn_2_porcentajes[2])\n",
        "  S2_2.append(attn_2_porcentajes[3])\n",
        "  S3_2.append(attn_2_porcentajes[4])\n",
        "  S4_2.append(attn_2_porcentajes[5])\n",
        "\n",
        "  saveDataExcel(\"map-1\",i,imag_names,melanoma,S0_1,S1_1,S2_1,S3_1,S4_1,lesion_1)\n",
        "  saveDataExcel(\"map-2\",i,imag_names,melanoma,S0_2,S1_2,S2_2,S3_2,S4_2, lesion_2)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}